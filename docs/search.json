[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nKai Stern\n\n\nApr 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nKai Stern\n\n\nApr 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThis is Project 1\n\n\nAn intro project.\n\n\n\n\n\n\nApr 4, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was designed to understand how changes in the perceived “price” of giving affect charitable behavior. Matching grant letters offered donors the opportunity to have their gifts matched by a leadership donor at varying rates, either $1:$1, $2:$1, or $3:$1. This effectively lowers the cost of providing a dollar to the charity. Additionally, the researchers randomized the stated size of the matching grant (e.g., $25,000 or $100,000) and varied the suggested donation amount based on past donor behavior. This allowed for a nuanced investigation of how framing and financial incentives influence both the likelihood of giving and the amount given.\nThe experiment was embedded in a real-world fundraising campaign conducted by a politically liberal nonprofit organization, making it a natural field experiment rather than a lab-based or hypothetical one. The study found that the mere presence of a matching grant substantially increased response rates and average donations. However, increasing the match ratio above 1:1 had no significant additional effect, suggesting that psychological framing, rather than purely economic incentives, plays a key role in donor decision-making. These findings have important implications for fundraising strategy, behavioral economics, and the broader understanding of prosocial behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/index.html#introduction",
    "href": "blog/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was designed to understand how changes in the perceived “price” of giving affect charitable behavior. Matching grant letters offered donors the opportunity to have their gifts matched by a leadership donor at varying rates, either $1:$1, $2:$1, or $3:$1. This effectively lowers the cost of providing a dollar to the charity. Additionally, the researchers randomized the stated size of the matching grant (e.g., $25,000 or $100,000) and varied the suggested donation amount based on past donor behavior. This allowed for a nuanced investigation of how framing and financial incentives influence both the likelihood of giving and the amount given.\nThe experiment was embedded in a real-world fundraising campaign conducted by a politically liberal nonprofit organization, making it a natural field experiment rather than a lab-based or hypothetical one. The study found that the mere presence of a matching grant substantially increased response rates and average donations. However, increasing the match ratio above 1:1 had no significant additional effect, suggesting that psychological framing, rather than purely economic incentives, plays a key role in donor decision-making. These findings have important implications for fundraising strategy, behavioral economics, and the broader understanding of prosocial behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/index.html#data",
    "href": "blog/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.describe()\n\nThe history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n# Define variables to test\nvariables = {\n    \"pwhite\": \"Proportion White\",\n    \"pblack\": \"Proportion Black\",\n    \"page18_39\": \"Proportion Age 18-39\",\n    \"ave_hh_sz\": \"Average Household Size\"\n}\n\nresults = []\n\nfor var, label in variables.items():\n    # Subset data\n    treat = df[df[\"treatment\"] == 1][var].dropna()\n    control = df[df[\"treatment\"] == 0][var].dropna()\n\n    # Manual t-test\n    diff = treat.mean() - control.mean()\n    se = np.sqrt(treat.var(ddof=1)/len(treat) + control.var(ddof=1)/len(control))\n    t_stat = diff / se\n    df_total = len(treat) + len(control) - 2\n    p_val_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), df=df_total))\n\n    # Regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params[\"treatment\"]\n    p_val_reg = model.pvalues[\"treatment\"]\n\n    results.append({\n        \"Variable\": label,\n        \"Diff (Treat - Control)\": diff,\n        \"T-test p-value\": p_val_ttest,\n        \"Regression Coef\": coef,\n        \"Regression p-value\": p_val_reg\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nDiff (Treat - Control)\nT-test p-value\nRegression Coef\nRegression p-value\n\n\n\n\n0\nProportion White\n-0.000913\n0.576130\n-0.000913\n0.575308\n\n\n1\nProportion Black\n0.000129\n0.922294\n0.000129\n0.921935\n\n\n2\nProportion Age 18-39\n-0.000124\n0.901123\n-0.000124\n0.901029\n\n\n3\nAverage Household Size\n0.003012\n0.410313\n0.003012\n0.409801\n\n\n\n\n\n\n\nI tested four demographic variables: proportion white, proportion black, proportion aged 18–39, and average household size for balance between treatment and control groups using both two-sample t-tests and simple linear regressions. In all cases, the p-values were well above the 0.05 threshold, indicating no statistically significant differences between groups. Additionally, the t-test differences and regression coefficients matched exactly, confirming consistency between methods. These results suggest that the randomization was successful and that the treatment and control groups are comparable on these baseline characteristics, supporting the validity of subsequent causal inferences."
  },
  {
    "objectID": "blog/project1/index.html#experimental-results",
    "href": "blog/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Calculate donation rates\nresponse_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\nvalues = response_rates.values\n\n# Plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(labels, values, edgecolor='black')\nplt.ylabel('Proportion Donated')\nplt.title('Donation Response Rate by Group')\n\nText(0.5, 1.0, 'Donation Response Rate by Group')\n\n\n\n\n\n\n\n\n\nThe bar charts demonstrate an approximately 5% difference between the proportions of donors in the treatment and control groups. The control group is made up of around 17% of donors while the treatment group is around 22%.\n\n# Subset data\ngave_treat = df[df['treatment'] == 1]['gave']\ngave_control = df[df['treatment'] == 0]['gave']\n\n# Means for reference\nmean_treat = gave_treat.mean()\nmean_control = gave_control.mean()\ndiff = mean_treat - mean_control\n\n# Manual t-test for binary outcome\nn1, n2 = len(gave_treat), len(gave_control)\np1, p2 = mean_treat, mean_control\nvar1 = p1 * (1 - p1)\nvar2 = p2 * (1 - p2)\nse = np.sqrt(var1/n1 + var2/n2)\nt_stat = diff / se\ndf_total = n1 + n2 - 2\np_value_t = 2 * (1 - stats.t.cdf(np.abs(t_stat), df=df_total))\n\n# Regression: gave ~ treatment\nreg = smf.ols('gave ~ treatment', data=df).fit()\nreg_coef = reg.params['treatment']\nreg_pval = reg.pvalues['treatment']\n\n# Display results\n{\n    \"Control Mean\": mean_control,\n    \"Treatment Mean\": mean_treat,\n    \"Difference\": diff,\n    \"T-statistic\": t_stat,\n    \"T-test p-value\": p_value_t,\n    \"Regression Coefficient\": reg_coef,\n    \"Regression p-value\": reg_pval\n}\n\n{'Control Mean': np.float64(0.017858212980164198),\n 'Treatment Mean': np.float64(0.02203856749311295),\n 'Difference': np.float64(0.00418035451294875),\n 'T-statistic': np.float64(3.209540056375026),\n 'T-test p-value': np.float64(0.001330312711992132),\n 'Regression Coefficient': np.float64(0.004180354512949392),\n 'Regression p-value': np.float64(0.0019274025949017077)}\n\n\nI tested whether people who received a fundraising letter with a matching donation offer were more likely to donate compared to those who received a standard letter. A t-test shows that the treatment group had a statistically significantly higher donation rate than the control group. This result is confirmed by a linear regression, where the coefficient on the treatment variable closely matches the observed difference in means and is statistically significant.\nIn practical terms, just mentioning that a matching donation is available makes people more likely to give. Even a small change in framing (e.g., adding a single paragraph about a match) meaningfully influences behavior. This supports the idea that people are motivated not just by the financial impact of their gift, but by social signals like the opportunity to “unlock” funds from another donor. It also reinforces how seemingly minor tweaks in messaging can have outsized effects in fundraising campaigns.\n\ndef summarize_model(model, dep_var=\"y\"):\n    coef = model.params\n    se = model.bse\n    pval = model.pvalues\n    zval = model.tvalues  # also t-values for OLS\n    ci = model.conf_int()\n    n = int(model.nobs)\n\n    is_probit = hasattr(model, 'prsquared')  # True for Probit/Logit, not for OLS\n\n    if is_probit:\n        print(f\"### Probit Regression: {dep_var} ~ [predictors]\")\n        print(f\"**Sample size:** {n}\")\n        print(f\"**Pseudo R-squared:** {model.prsquared:.4f}\")\n        print(f\"**Log-likelihood:** {model.llf:.1f}\")\n        print(f\"**Model significance (LLR p-value):** {model.llr_pvalue:.4f}\")\n    else:\n        print(f\"### OLS Regression: {dep_var} ~ [predictors]\")\n        print(f\"**Sample size:** {n}\")\n        print(f\"**R-squared:** {model.rsquared:.4f}\")\n\n    print(\"\\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\")\n    print(\"|------------|-------------|------------|-----------|---------|-------------------|\")\n\n    for var in coef.index:\n        ci_lower = ci.loc[var, 0]\n        ci_upper = ci.loc[var, 1]\n        print(f\"| {var:&lt;10} | {coef[var]:&gt;11.4f} | {se[var]:&gt;10.4f} | {zval[var]:&gt;9.2f} | {pval[var]:&gt;7.4f} | [{ci_lower:.3f}, {ci_upper:.3f}] |\")\n\n\n# Probit regression\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\nsummarize_model(probit_model, 'gave')\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n### Probit Regression: gave ~ [predictors]\n**Sample size:** 50083\n**Pseudo R-squared:** 0.0010\n**Log-likelihood:** -5030.5\n**Model significance (LLR p-value):** 0.0017\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |     -2.1001 |     0.0233 |    -90.07 |  0.0000 | [-2.146, -2.054] |\n| treatment  |      0.0868 |     0.0279 |      3.11 |  0.0019 | [0.032, 0.141] |\n\n\nI estimated a probit regression to examine whether assignment to the treatment group receiving a matching donation offer increased the likelihood that an individual made a charitable donation. The dependent variable was “gave”, a binary indicator equal to 1 if any donation was made. The key explanatory variable was treatment, equal to 1 for individuals who received a matching offer.\nThe probit model results show a positive and statistically significant coefficient of 0.0868 on the treatment variable (p = 0.002). This matches the findings reported in Table 3, Column 1 of Karlan & List (2007), where the coefficient on treatment is also approximately 0.087 and highly significant.\nThis result confirms that simply including a matching grant offer in a fundraising letter increases the probability of giving. The significance of the coefficient suggests that the effect is not due to chance. While the magnitude of the effect is modest in absolute terms, its consistency across t-tests, OLS, and probit models strengthens the evidence that framing a donation as being matched can meaningfully influence donor behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Limit to only people who received a treatment letter (match offered)\ntreated = df[df['treatment'] == 1]\n\n# Get donation responses by match ratio\ngave_1to1 = treated[treated['ratio'] == 1]['gave']\ngave_2to1 = treated[treated['ratio'] == 2]['gave']\ngave_3to1 = treated[treated['ratio'] == 3]['gave']\n\n# Calculate means for each group\nmean_1 = gave_1to1.mean()\nmean_2 = gave_2to1.mean()\nmean_3 = gave_3to1.mean()\n\n# Run t-tests\nt_2_vs_1 = ttest_ind(gave_2to1, gave_1to1)\nt_3_vs_2 = ttest_ind(gave_3to1, gave_2to1)\nt_3_vs_1 = ttest_ind(gave_3to1,gave_1to1)\n\n{\n    \"1:1 Match Rate\": mean_1,\n    \"2:1 Match Rate\": mean_2,\n    \"3:1 Match Rate\": mean_3,\n    \"p-value: 2:1 vs 1:1\": t_2_vs_1.pvalue,\n    \"p-value: 3:1 vs 2:1\": t_3_vs_2.pvalue,\n    \"p-value: 3:1 vs 1:1\": t_3_vs_1.pvalue\n}\n\n{'1:1 Match Rate': np.float64(0.020749124225276205),\n '2:1 Match Rate': np.float64(0.0226333752469912),\n '3:1 Match Rate': np.float64(0.022733399227244138),\n 'p-value: 2:1 vs 1:1': np.float64(0.33453168549723933),\n 'p-value: 3:1 vs 2:1': np.float64(0.9600305283739325),\n 'p-value: 3:1 vs 1:1': np.float64(0.31010466370866724)}\n\n\nTo assess whether larger match ratios increase donation rates, I performed a series of t-tests comparing response rates among individuals assigned to 1:1, 2:1, and 3:1 match treatment groups. The donation rate was approximately 2.07% for the 1:1 group, 2.26% for 2:1, and 2.27% for 3:1. Although there is a small increase in the average response rate as the match ratio increases, none of the differences are statistically significant: the p-value comparing 2:1 to 1:1 is 0.335, and for 3:1 vs. 2:1 it is 0.960. Even the largest comparison (3:1 vs. 1:1) yields a p-value of 0.310, far above the conventional 0.05 threshold for significance.\nThese results support the authors’ “figures suggest” comment on page 8 of the paper: while the raw response rates rise slightly with higher match ratios, the increases are not statistically meaningful. This suggests that once a match is offered, increasing the size of that match even up to 3:1 does not further motivate donors to give\n\ntreated = df[df['treatment'] == 1].copy()\n\n# Create dummy variables \ntreated['ratio1'] = (treated['ratio'] == 1).astype(int)\ntreated['ratio2'] = (treated['ratio'] == 2).astype(int)\ntreated['ratio3'] = (treated['ratio'] == 3).astype(int)\n\n# Regression: gave ~ ratio2 + ratio3 \nratio_reg = smf.ols('gave ~ ratio2 + ratio3', data=treated).fit()\n\nsummarize_model(ratio_reg, 'gave')\n\n### OLS Regression: gave ~ [predictors]\n**Sample size:** 33396\n**R-squared:** 0.0000\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |      0.0207 |     0.0014 |     14.91 |  0.0000 | [0.018, 0.023] |\n| ratio2     |      0.0019 |     0.0020 |      0.96 |  0.3383 | [-0.002, 0.006] |\n| ratio3     |      0.0020 |     0.0020 |      1.01 |  0.3133 | [-0.002, 0.006] |\n\n\nTo assess whether the size of the match ratio influenced donation behavior, I regressed the binary outcome variable gave on dummy variables for 2:1 and 3:1 match ratios, using the 1:1 match as the baseline. The results show that neither the 2:1 nor 3:1 match ratios had a statistically significant effect on the likelihood of donating compared to the 1:1 match. The coefficient for ratio2 was 0.0019 (p = 0.338), and for ratio3 it was 0.0020 (p = 0.313), both with confidence intervals that include zero. The intercept, representing the baseline 1:1 match group, was 0.0207, consistent with earlier descriptive statistics. These findings confirm that increasing the size of the match beyond 1:1 does not meaningfully increase donation rates, reinforcing the paper’s conclusion that the presence of a match offer matters more than its size.\n\nmean_1 = gave_1to1.mean()\nmean_2 = gave_2to1.mean()\nmean_3 = gave_3to1.mean()\n\n# Raw differences\nraw_diff_2_vs_1 = mean_2 - mean_1\nraw_diff_3_vs_2 = mean_3 - mean_2\n\n# From regression results\ncoef_2 = ratio_reg.params['ratio2']\ncoef_3 = ratio_reg.params['ratio3']\n\n# Fitted differences (1:1 is baseline = intercept)\nfitted_diff_2_vs_1 = coef_2\nfitted_diff_3_vs_2 = coef_3 - coef_2\n\n{\n    \"Raw Difference (2:1 - 1:1)\": raw_diff_2_vs_1,\n    \"Raw Difference (3:1 - 2:1)\": raw_diff_3_vs_2,\n    \"Fitted Difference (2:1 - 1:1)\": fitted_diff_2_vs_1,\n    \"Fitted Difference (3:1 - 2:1)\": fitted_diff_3_vs_2\n}\n\n{'Raw Difference (2:1 - 1:1)': np.float64(0.0018842510217149944),\n 'Raw Difference (3:1 - 2:1)': np.float64(0.00010002398025293902),\n 'Fitted Difference (2:1 - 1:1)': np.float64(0.0018842510217148354),\n 'Fitted Difference (3:1 - 2:1)': np.float64(0.00010002398025296178)}\n\n\nTo further assess the effect of increasing the match ratio on donation rates, I calculated both raw and regression-based differences in response rates. The raw data show a donation rate of 2.07% for the 1:1 group, 2.26% for the 2:1 group, and 2.27% for the 3:1 group. The difference between 2:1 and 1:1 is approximately 0.0019, while the difference between 3:1 and 2:1 is just 0.0001. These match almost exactly the fitted differences obtained from the regression coefficients (0.0019 and 0.0001, respectively). The consistency between the raw and model-based estimates reinforces the conclusion that larger match ratios do not meaningfully increase the likelihood of giving. The small and statistically insignificant differences confirm that the presence of a match matters, but its generosity does not seem to influence donor behavior beyond that initial effect.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Bivariate regression: total amount donated ~ treatment\namount_reg = smf.ols('amount ~ treatment', data=df).fit()\nsummarize_model(amount_reg, 'amount')\n\n### OLS Regression: amount ~ [predictors]\n**Sample size:** 50083\n**R-squared:** 0.0001\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |      0.8133 |     0.0674 |     12.06 |  0.0000 | [0.681, 0.945] |\n| treatment  |      0.1536 |     0.0826 |      1.86 |  0.0628 | [-0.008, 0.315] |\n\n\nTo assess whether offering a matching donation influenced not just the likelihood of giving but also the amount donated, I regressed the dollar amount of contributions on the treatment assignment indicator. The results show that the average donation in the control group was $0.81, as reflected in the intercept. Individuals in the treatment group gave $0.15 more on average, though this difference is not statistically significant at the 5% level (p = 0.063). While the coefficient is positive and suggestive of a modest increase in donation size, the lack of statistical significance means we cannot confidently conclude that the treatment had a reliable effect on donation amounts. This suggests that the primary effect of the matching offer was to increase participation, rather than the average amount given per donor.\n\ndonors = df[df['gave']&gt;0]\n\namount_reg2 = smf.ols('amount ~ treatment', data=donors).fit()\namount_reg2.summary()\n\nsummarize_model(amount_reg2, 'amount')\n\n### OLS Regression: amount ~ [predictors]\n**Sample size:** 1034\n**R-squared:** 0.0003\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |     45.5403 |     2.4234 |     18.79 |  0.0000 | [40.785, 50.296] |\n| treatment  |     -1.6684 |     2.8724 |     -0.58 |  0.5615 | [-7.305, 3.968] |\n\n\nTo understand whether the treatment influenced how much people donated, conditional on having donated, I restricted the dataset to individuals who made a donation (gave &gt; 0) and regressed amount on the treatment indicator. The results show that the average donation amount in the control group was approximately $45.54, while the treatment group gave $1.67 less on average, according to the regression coefficient. However, this difference is not statistically significant (p = 0.561), and the 95% confidence interval includes zero (−7.31 to 3.97). This indicates that among those who did choose to donate, being offered a matching grant did not significantly affect the donation amount.\n\n# Separate treatment and control donors\ntreat_donors = donors[donors['treatment'] == 1]['amount']\ncontrol_donors = donors[donors['treatment'] == 0]['amount']\n\n# Calculate means\nmean_treat = treat_donors.mean()\nmean_control = control_donors.mean()\n\n# Plot: Control Group\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.hist(control_donors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_control:.2f}')\nplt.title(\"Control Group Donations\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\n# Plot: Treatment Group\nplt.subplot(1, 2, 2)\nplt.hist(treat_donors, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.axvline(mean_treat, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_treat:.2f}')\nplt.title(\"Treatment Group Donations\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show the distribution of donation amounts among individuals who gave, separated by treatment and control groups. While both distributions are right-skewed, the average donation is slightly lower in the treatment group ($43.87) than in the control group ($45.54), indicating that the match offer did not increase conditional donation amounts."
  },
  {
    "objectID": "blog/project1/index.html#simulation-experiment",
    "href": "blog/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulate donation behavior: Bernoulli draws\n# 100,000 from control group, p = 0.018\n# 10,000 from treatment group, p = 0.022\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(1, 0.018, 100000)\ntreat_draws = np.random.binomial(1, 0.022, 10000)\n\n# Calculate pointwise differences between treatment and control draws\ndiffs = treat_draws - control_draws[:10000]  # align sizes\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot cumulative average\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.022 - 0.018)')\nplt.title(\"Law of Large Numbers: Cumulative Average of Simulated Differences\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot illustrates the Law of Large Numbers by showing how the cumulative average of simulated differences in donation behavior between treatment and control groups stabilizes as the sample size increases. Initially, the cumulative average fluctuates widely due to random variation in small samples, but as more observations accumulate, the average converges toward the true difference in population means: 0.004 (marked by the red dashed line). This visual evidence confirms that with a large enough sample, the observed difference in donation rates between treatment and control becomes a reliable estimate of the actual treatment effect.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulation setup\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Function to simulate one sample difference\ndef simulate_diffs(n, p1, p2, reps=1000):\n    diffs = []\n    for _ in range(reps):\n        c = np.random.binomial(1, p1, n)\n        t = np.random.binomial(1, p2, n)\n        diffs.append(np.mean(t) - np.mean(c))\n    return np.array(diffs)\n\n# Generate and plot\nplt.figure(figsize=(12, 10))\n\nfor i, n in enumerate(sample_sizes, 1):\n    diffs = simulate_diffs(n, p_control, p_treatment)\n    plt.subplot(2, 2, i)\n    plt.hist(diffs, bins=30, edgecolor='black', alpha=0.7, density=True)\n    plt.axvline(0, color='black', linestyle='--', linewidth=1, label='Zero')\n    plt.axvline(0.004, color='red', linestyle='--', linewidth=2, label='True Diff = 0.004')\n    plt.title(f\"Sample Size = {n}\")\n    plt.xlabel(\"Difference in Means\")\n    plt.ylabel(\"Density\")\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese four histograms illustrate the Central Limit Theorem by showing the sampling distribution of the difference in means between treatment and control groups across varying sample sizes (50, 200, 500, and 1000). At smaller sample sizes (e.g., 50), the distribution is wide and irregular, and zero frequently appears near the center—indicating that we might observe no difference simply due to sampling variability. As the sample size increases, the distribution becomes more concentrated and symmetric, and the center of the distribution shifts closer to the true difference of 0.004 (indicated by the red dashed line). By the time we reach a sample size of 1000, the sampling distribution is tightly centered around the true effect, and zero lies in the tail rather than the center. This pattern highlights how increasing sample size leads to more precise and reliable estimates, reducing the likelihood that random chance obscures true treatment effects"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kai’s Stern",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was designed to understand how changes in the perceived “price” of giving affect charitable behavior. Matching grant letters offered donors the opportunity to have their gifts matched by a leadership donor at varying rates, either $1:$1, $2:$1, or $3:$1. This effectively lowers the cost of providing a dollar to the charity. Additionally, the researchers randomized the stated size of the matching grant (e.g., $25,000 or $100,000) and varied the suggested donation amount based on past donor behavior. This allowed for a nuanced investigation of how framing and financial incentives influence both the likelihood of giving and the amount given.\nThe experiment was embedded in a real-world fundraising campaign conducted by a politically liberal nonprofit organization, making it a natural field experiment rather than a lab-based or hypothetical one. The study found that the mere presence of a matching grant substantially increased response rates and average donations. However, increasing the match ratio above 1:1 had no significant additional effect, suggesting that psychological framing, rather than purely economic incentives, plays a key role in donor decision-making. These findings have important implications for fundraising strategy, behavioral economics, and the broader understanding of prosocial behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was designed to understand how changes in the perceived “price” of giving affect charitable behavior. Matching grant letters offered donors the opportunity to have their gifts matched by a leadership donor at varying rates, either $1:$1, $2:$1, or $3:$1. This effectively lowers the cost of providing a dollar to the charity. Additionally, the researchers randomized the stated size of the matching grant (e.g., $25,000 or $100,000) and varied the suggested donation amount based on past donor behavior. This allowed for a nuanced investigation of how framing and financial incentives influence both the likelihood of giving and the amount given.\nThe experiment was embedded in a real-world fundraising campaign conducted by a politically liberal nonprofit organization, making it a natural field experiment rather than a lab-based or hypothetical one. The study found that the mere presence of a matching grant substantially increased response rates and average donations. However, increasing the match ratio above 1:1 had no significant additional effect, suggesting that psychological framing, rather than purely economic incentives, plays a key role in donor decision-making. These findings have important implications for fundraising strategy, behavioral economics, and the broader understanding of prosocial behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.describe()\n\nThe history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n# Define variables to test\nvariables = {\n    \"pwhite\": \"Proportion White\",\n    \"pblack\": \"Proportion Black\",\n    \"page18_39\": \"Proportion Age 18-39\",\n    \"ave_hh_sz\": \"Average Household Size\"\n}\n\nresults = []\n\nfor var, label in variables.items():\n    # Subset data\n    treat = df[df[\"treatment\"] == 1][var].dropna()\n    control = df[df[\"treatment\"] == 0][var].dropna()\n\n    # Manual t-test\n    diff = treat.mean() - control.mean()\n    se = np.sqrt(treat.var(ddof=1)/len(treat) + control.var(ddof=1)/len(control))\n    t_stat = diff / se\n    df_total = len(treat) + len(control) - 2\n    p_val_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), df=df_total))\n\n    # Regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params[\"treatment\"]\n    p_val_reg = model.pvalues[\"treatment\"]\n\n    results.append({\n        \"Variable\": label,\n        \"Diff (Treat - Control)\": diff,\n        \"T-test p-value\": p_val_ttest,\n        \"Regression Coef\": coef,\n        \"Regression p-value\": p_val_reg\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nDiff (Treat - Control)\nT-test p-value\nRegression Coef\nRegression p-value\n\n\n\n\n0\nProportion White\n-0.000913\n0.576130\n-0.000913\n0.575308\n\n\n1\nProportion Black\n0.000129\n0.922294\n0.000129\n0.921935\n\n\n2\nProportion Age 18-39\n-0.000124\n0.901123\n-0.000124\n0.901029\n\n\n3\nAverage Household Size\n0.003012\n0.410313\n0.003012\n0.409801\n\n\n\n\n\n\n\nI tested four demographic variables: proportion white, proportion black, proportion aged 18–39, and average household size for balance between treatment and control groups using both two-sample t-tests and simple linear regressions. In all cases, the p-values were well above the 0.05 threshold, indicating no statistically significant differences between groups. Additionally, the t-test differences and regression coefficients matched exactly, confirming consistency between methods. These results suggest that the randomization was successful and that the treatment and control groups are comparable on these baseline characteristics, supporting the validity of subsequent causal inferences."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Calculate donation rates\nresponse_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\nvalues = response_rates.values\n\n# Plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(labels, values, edgecolor='black')\nplt.ylabel('Proportion Donated')\nplt.title('Donation Response Rate by Group')\n\nText(0.5, 1.0, 'Donation Response Rate by Group')\n\n\n\n\n\n\n\n\n\nThe bar charts demonstrate an approximately 5% difference between the proportions of donors in the treatment and control groups. The control group is made up of around 17% of donors while the treatment group is around 22%.\n\n# Subset data\ngave_treat = df[df['treatment'] == 1]['gave']\ngave_control = df[df['treatment'] == 0]['gave']\n\n# Means for reference\nmean_treat = gave_treat.mean()\nmean_control = gave_control.mean()\ndiff = mean_treat - mean_control\n\n# Manual t-test for binary outcome\nn1, n2 = len(gave_treat), len(gave_control)\np1, p2 = mean_treat, mean_control\nvar1 = p1 * (1 - p1)\nvar2 = p2 * (1 - p2)\nse = np.sqrt(var1/n1 + var2/n2)\nt_stat = diff / se\ndf_total = n1 + n2 - 2\np_value_t = 2 * (1 - stats.t.cdf(np.abs(t_stat), df=df_total))\n\n# Regression: gave ~ treatment\nreg = smf.ols('gave ~ treatment', data=df).fit()\nreg_coef = reg.params['treatment']\nreg_pval = reg.pvalues['treatment']\n\n# Display results\n{\n    \"Control Mean\": mean_control,\n    \"Treatment Mean\": mean_treat,\n    \"Difference\": diff,\n    \"T-statistic\": t_stat,\n    \"T-test p-value\": p_value_t,\n    \"Regression Coefficient\": reg_coef,\n    \"Regression p-value\": reg_pval\n}\n\n{'Control Mean': np.float64(0.017858212980164198),\n 'Treatment Mean': np.float64(0.02203856749311295),\n 'Difference': np.float64(0.00418035451294875),\n 'T-statistic': np.float64(3.209540056375026),\n 'T-test p-value': np.float64(0.001330312711992132),\n 'Regression Coefficient': np.float64(0.004180354512949392),\n 'Regression p-value': np.float64(0.0019274025949017077)}\n\n\nI tested whether people who received a fundraising letter with a matching donation offer were more likely to donate compared to those who received a standard letter. A t-test shows that the treatment group had a statistically significantly higher donation rate than the control group. This result is confirmed by a linear regression, where the coefficient on the treatment variable closely matches the observed difference in means and is statistically significant.\nIn practical terms, just mentioning that a matching donation is available makes people more likely to give. Even a small change in framing (e.g., adding a single paragraph about a match) meaningfully influences behavior. This supports the idea that people are motivated not just by the financial impact of their gift, but by social signals like the opportunity to “unlock” funds from another donor. It also reinforces how seemingly minor tweaks in messaging can have outsized effects in fundraising campaigns.\n\ndef summarize_model(model, dep_var=\"y\"):\n    coef = model.params\n    se = model.bse\n    pval = model.pvalues\n    zval = model.tvalues  # also t-values for OLS\n    ci = model.conf_int()\n    n = int(model.nobs)\n\n    is_probit = hasattr(model, 'prsquared')  # True for Probit/Logit, not for OLS\n\n    if is_probit:\n        print(f\"### Probit Regression: {dep_var} ~ [predictors]\")\n        print(f\"**Sample size:** {n}\")\n        print(f\"**Pseudo R-squared:** {model.prsquared:.4f}\")\n        print(f\"**Log-likelihood:** {model.llf:.1f}\")\n        print(f\"**Model significance (LLR p-value):** {model.llr_pvalue:.4f}\")\n    else:\n        print(f\"### OLS Regression: {dep_var} ~ [predictors]\")\n        print(f\"**Sample size:** {n}\")\n        print(f\"**R-squared:** {model.rsquared:.4f}\")\n\n    print(\"\\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\")\n    print(\"|------------|-------------|------------|-----------|---------|-------------------|\")\n\n    for var in coef.index:\n        ci_lower = ci.loc[var, 0]\n        ci_upper = ci.loc[var, 1]\n        print(f\"| {var:&lt;10} | {coef[var]:&gt;11.4f} | {se[var]:&gt;10.4f} | {zval[var]:&gt;9.2f} | {pval[var]:&gt;7.4f} | [{ci_lower:.3f}, {ci_upper:.3f}] |\")\n\n\n# Probit regression\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\nsummarize_model(probit_model, 'gave')\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n### Probit Regression: gave ~ [predictors]\n**Sample size:** 50083\n**Pseudo R-squared:** 0.0010\n**Log-likelihood:** -5030.5\n**Model significance (LLR p-value):** 0.0017\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |     -2.1001 |     0.0233 |    -90.07 |  0.0000 | [-2.146, -2.054] |\n| treatment  |      0.0868 |     0.0279 |      3.11 |  0.0019 | [0.032, 0.141] |\n\n\nI estimated a probit regression to examine whether assignment to the treatment group receiving a matching donation offer increased the likelihood that an individual made a charitable donation. The dependent variable was “gave”, a binary indicator equal to 1 if any donation was made. The key explanatory variable was treatment, equal to 1 for individuals who received a matching offer.\nThe probit model results show a positive and statistically significant coefficient of 0.0868 on the treatment variable (p = 0.002). This matches the findings reported in Table 3, Column 1 of Karlan & List (2007), where the coefficient on treatment is also approximately 0.087 and highly significant.\nThis result confirms that simply including a matching grant offer in a fundraising letter increases the probability of giving. The significance of the coefficient suggests that the effect is not due to chance. While the magnitude of the effect is modest in absolute terms, its consistency across t-tests, OLS, and probit models strengthens the evidence that framing a donation as being matched can meaningfully influence donor behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Limit to only people who received a treatment letter (match offered)\ntreated = df[df['treatment'] == 1]\n\n# Get donation responses by match ratio\ngave_1to1 = treated[treated['ratio'] == 1]['gave']\ngave_2to1 = treated[treated['ratio'] == 2]['gave']\ngave_3to1 = treated[treated['ratio'] == 3]['gave']\n\n# Calculate means for each group\nmean_1 = gave_1to1.mean()\nmean_2 = gave_2to1.mean()\nmean_3 = gave_3to1.mean()\n\n# Run t-tests\nt_2_vs_1 = ttest_ind(gave_2to1, gave_1to1)\nt_3_vs_2 = ttest_ind(gave_3to1, gave_2to1)\nt_3_vs_1 = ttest_ind(gave_3to1,gave_1to1)\n\n{\n    \"1:1 Match Rate\": mean_1,\n    \"2:1 Match Rate\": mean_2,\n    \"3:1 Match Rate\": mean_3,\n    \"p-value: 2:1 vs 1:1\": t_2_vs_1.pvalue,\n    \"p-value: 3:1 vs 2:1\": t_3_vs_2.pvalue,\n    \"p-value: 3:1 vs 1:1\": t_3_vs_1.pvalue\n}\n\n{'1:1 Match Rate': np.float64(0.020749124225276205),\n '2:1 Match Rate': np.float64(0.0226333752469912),\n '3:1 Match Rate': np.float64(0.022733399227244138),\n 'p-value: 2:1 vs 1:1': np.float64(0.33453168549723933),\n 'p-value: 3:1 vs 2:1': np.float64(0.9600305283739325),\n 'p-value: 3:1 vs 1:1': np.float64(0.31010466370866724)}\n\n\nTo assess whether larger match ratios increase donation rates, I performed a series of t-tests comparing response rates among individuals assigned to 1:1, 2:1, and 3:1 match treatment groups. The donation rate was approximately 2.07% for the 1:1 group, 2.26% for 2:1, and 2.27% for 3:1. Although there is a small increase in the average response rate as the match ratio increases, none of the differences are statistically significant: the p-value comparing 2:1 to 1:1 is 0.335, and for 3:1 vs. 2:1 it is 0.960. Even the largest comparison (3:1 vs. 1:1) yields a p-value of 0.310, far above the conventional 0.05 threshold for significance.\nThese results support the authors’ “figures suggest” comment on page 8 of the paper: while the raw response rates rise slightly with higher match ratios, the increases are not statistically meaningful. This suggests that once a match is offered, increasing the size of that match even up to 3:1 does not further motivate donors to give\n\ntreated = df[df['treatment'] == 1].copy()\n\n# Create dummy variables \ntreated['ratio1'] = (treated['ratio'] == 1).astype(int)\ntreated['ratio2'] = (treated['ratio'] == 2).astype(int)\ntreated['ratio3'] = (treated['ratio'] == 3).astype(int)\n\n# Regression: gave ~ ratio2 + ratio3 \nratio_reg = smf.ols('gave ~ ratio2 + ratio3', data=treated).fit()\n\nsummarize_model(ratio_reg, 'gave')\n\n### OLS Regression: gave ~ [predictors]\n**Sample size:** 33396\n**R-squared:** 0.0000\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |      0.0207 |     0.0014 |     14.91 |  0.0000 | [0.018, 0.023] |\n| ratio2     |      0.0019 |     0.0020 |      0.96 |  0.3383 | [-0.002, 0.006] |\n| ratio3     |      0.0020 |     0.0020 |      1.01 |  0.3133 | [-0.002, 0.006] |\n\n\nTo assess whether the size of the match ratio influenced donation behavior, I regressed the binary outcome variable gave on dummy variables for 2:1 and 3:1 match ratios, using the 1:1 match as the baseline. The results show that neither the 2:1 nor 3:1 match ratios had a statistically significant effect on the likelihood of donating compared to the 1:1 match. The coefficient for ratio2 was 0.0019 (p = 0.338), and for ratio3 it was 0.0020 (p = 0.313), both with confidence intervals that include zero. The intercept, representing the baseline 1:1 match group, was 0.0207, consistent with earlier descriptive statistics. These findings confirm that increasing the size of the match beyond 1:1 does not meaningfully increase donation rates, reinforcing the paper’s conclusion that the presence of a match offer matters more than its size.\n\nmean_1 = gave_1to1.mean()\nmean_2 = gave_2to1.mean()\nmean_3 = gave_3to1.mean()\n\n# Raw differences\nraw_diff_2_vs_1 = mean_2 - mean_1\nraw_diff_3_vs_2 = mean_3 - mean_2\n\n# From regression results\ncoef_2 = ratio_reg.params['ratio2']\ncoef_3 = ratio_reg.params['ratio3']\n\n# Fitted differences (1:1 is baseline = intercept)\nfitted_diff_2_vs_1 = coef_2\nfitted_diff_3_vs_2 = coef_3 - coef_2\n\n{\n    \"Raw Difference (2:1 - 1:1)\": raw_diff_2_vs_1,\n    \"Raw Difference (3:1 - 2:1)\": raw_diff_3_vs_2,\n    \"Fitted Difference (2:1 - 1:1)\": fitted_diff_2_vs_1,\n    \"Fitted Difference (3:1 - 2:1)\": fitted_diff_3_vs_2\n}\n\n{'Raw Difference (2:1 - 1:1)': np.float64(0.0018842510217149944),\n 'Raw Difference (3:1 - 2:1)': np.float64(0.00010002398025293902),\n 'Fitted Difference (2:1 - 1:1)': np.float64(0.0018842510217148354),\n 'Fitted Difference (3:1 - 2:1)': np.float64(0.00010002398025296178)}\n\n\nTo further assess the effect of increasing the match ratio on donation rates, I calculated both raw and regression-based differences in response rates. The raw data show a donation rate of 2.07% for the 1:1 group, 2.26% for the 2:1 group, and 2.27% for the 3:1 group. The difference between 2:1 and 1:1 is approximately 0.0019, while the difference between 3:1 and 2:1 is just 0.0001. These match almost exactly the fitted differences obtained from the regression coefficients (0.0019 and 0.0001, respectively). The consistency between the raw and model-based estimates reinforces the conclusion that larger match ratios do not meaningfully increase the likelihood of giving. The small and statistically insignificant differences confirm that the presence of a match matters, but its generosity does not seem to influence donor behavior beyond that initial effect.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Bivariate regression: total amount donated ~ treatment\namount_reg = smf.ols('amount ~ treatment', data=df).fit()\nsummarize_model(amount_reg, 'amount')\n\n### OLS Regression: amount ~ [predictors]\n**Sample size:** 50083\n**R-squared:** 0.0001\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |      0.8133 |     0.0674 |     12.06 |  0.0000 | [0.681, 0.945] |\n| treatment  |      0.1536 |     0.0826 |      1.86 |  0.0628 | [-0.008, 0.315] |\n\n\nTo assess whether offering a matching donation influenced not just the likelihood of giving but also the amount donated, I regressed the dollar amount of contributions on the treatment assignment indicator. The results show that the average donation in the control group was $0.81, as reflected in the intercept. Individuals in the treatment group gave $0.15 more on average, though this difference is not statistically significant at the 5% level (p = 0.063). While the coefficient is positive and suggestive of a modest increase in donation size, the lack of statistical significance means we cannot confidently conclude that the treatment had a reliable effect on donation amounts. This suggests that the primary effect of the matching offer was to increase participation, rather than the average amount given per donor.\n\ndonors = df[df['gave']&gt;0]\n\namount_reg2 = smf.ols('amount ~ treatment', data=donors).fit()\namount_reg2.summary()\n\nsummarize_model(amount_reg2, 'amount')\n\n### OLS Regression: amount ~ [predictors]\n**Sample size:** 1034\n**R-squared:** 0.0003\n\n| Variable   | Coefficient | Std. Error | z/t-value | p-value | 95% CI            |\n|------------|-------------|------------|-----------|---------|-------------------|\n| Intercept  |     45.5403 |     2.4234 |     18.79 |  0.0000 | [40.785, 50.296] |\n| treatment  |     -1.6684 |     2.8724 |     -0.58 |  0.5615 | [-7.305, 3.968] |\n\n\nTo understand whether the treatment influenced how much people donated, conditional on having donated, I restricted the dataset to individuals who made a donation (gave &gt; 0) and regressed amount on the treatment indicator. The results show that the average donation amount in the control group was approximately $45.54, while the treatment group gave $1.67 less on average, according to the regression coefficient. However, this difference is not statistically significant (p = 0.561), and the 95% confidence interval includes zero (−7.31 to 3.97). This indicates that among those who did choose to donate, being offered a matching grant did not significantly affect the donation amount.\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n# Separate treatment and control donors\ntreat_donors = donors[donors['treatment'] == 1]['amount']\ncontrol_donors = donors[donors['treatment'] == 0]['amount']\n\n# Calculate means\nmean_treat = treat_donors.mean()\nmean_control = control_donors.mean()\n\n# Plot: Control Group\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.hist(control_donors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_control:.2f}')\nplt.title(\"Control Group Donations\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\n# Plot: Treatment Group\nplt.subplot(1, 2, 2)\nplt.hist(treat_donors, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.axvline(mean_treat, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_treat:.2f}')\nplt.title(\"Treatment Group Donations\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show the distribution of donation amounts among individuals who gave, separated by treatment and control groups. While both distributions are right-skewed, the average donation is slightly lower in the treatment group ($43.87) than in the control group ($45.54), indicating that the match offer did not increase conditional donation amounts."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulate donation behavior: Bernoulli draws\n# 100,000 from control group, p = 0.018\n# 10,000 from treatment group, p = 0.022\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(1, 0.018, 100000)\ntreat_draws = np.random.binomial(1, 0.022, 10000)\n\n# Calculate pointwise differences between treatment and control draws\ndiffs = treat_draws - control_draws[:10000]  # align sizes\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot cumulative average\nplt.figure(figsize=(8, 4))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.022 - 0.018)')\nplt.title(\"Law of Large Numbers: Cumulative Average of Simulated Differences\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot illustrates the Law of Large Numbers by showing how the cumulative average of simulated differences in donation behavior between treatment and control groups stabilizes as the sample size increases. Initially, the cumulative average fluctuates widely due to random variation in small samples, but as more observations accumulate, the average converges toward the true difference in population means: 0.004 (marked by the red dashed line). This visual evidence confirms that with a large enough sample, the observed difference in donation rates between treatment and control becomes a reliable estimate of the actual treatment effect.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulation setup\nnp.random.seed(42)\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Function to simulate one sample difference\ndef simulate_diffs(n, p1, p2, reps=1000):\n    diffs = []\n    for _ in range(reps):\n        c = np.random.binomial(1, p1, n)\n        t = np.random.binomial(1, p2, n)\n        diffs.append(np.mean(t) - np.mean(c))\n    return np.array(diffs)\n\n# Generate and plot\nplt.figure(figsize=(12, 10))\n\nfor i, n in enumerate(sample_sizes, 1):\n    diffs = simulate_diffs(n, p_control, p_treatment)\n    plt.subplot(2, 2, i)\n    plt.hist(diffs, bins=30, edgecolor='black', alpha=0.7, density=True)\n    plt.axvline(0, color='black', linestyle='--', linewidth=1, label='Zero')\n    plt.axvline(0.004, color='red', linestyle='--', linewidth=2, label='True Diff = 0.004')\n    plt.title(f\"Sample Size = {n}\")\n    plt.xlabel(\"Difference in Means\")\n    plt.ylabel(\"Density\")\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese four histograms illustrate the Central Limit Theorem by showing the sampling distribution of the difference in means between treatment and control groups across varying sample sizes (50, 200, 500, and 1000). At smaller sample sizes (e.g., 50), the distribution is wide and irregular, and zero frequently appears near the center—indicating that we might observe no difference simply due to sampling variability. As the sample size increases, the distribution becomes more concentrated and symmetric, and the center of the distribution shifts closer to the true difference of 0.004 (indicated by the red dashed line). By the time we reach a sample size of 1000, the sampling distribution is tightly centered around the true effect, and zero lies in the tail rather than the center. This pattern highlights how increasing sample size leads to more precise and reliable estimates, reducing the likelihood that random chance obscures true treatment effects"
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "This is project 2\nx = 10 print(x)"
  }
]